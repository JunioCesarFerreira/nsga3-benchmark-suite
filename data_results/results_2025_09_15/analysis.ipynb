{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e011853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReanÃ¡lise concluÃ­da. Resultados salvos em reanalyzed\\experiment7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from analysis.coverege_per_niche import count_points_per_niche_dtlz2, analyze_niche_distribution\n",
    "from utils.generate_points import generate_reference_points\n",
    "\n",
    "# --- CONFIG ---\n",
    "EXPERIMENT = \"experiment7\"\n",
    "RESULTS_DIR = Path(EXPERIMENT)   # deve rodar dentro de \"results/\"\n",
    "OUTPUT_DIR = Path(\"reanalyzed\") / EXPERIMENT\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Raios que vocÃª quer testar\n",
    "RADII = [0.15, 0.20, 0.25, 0.3, 0.35]\n",
    "\n",
    "# --- FUNÃ‡Ã•ES ---\n",
    "\n",
    "def reanalyze_coverage_for_radius(pareto_front, ref_pts, radius):\n",
    "    ptin, ptout = count_points_per_niche_dtlz2(pareto_front, ref_pts, radius)\n",
    "    niche_metrics = analyze_niche_distribution(ptin, ptout)\n",
    "    return {\n",
    "        \"radius\": radius,\n",
    "        \"points_in\": ptin.tolist(),\n",
    "        \"points_out\": ptout,\n",
    "        **niche_metrics\n",
    "    }\n",
    "\n",
    "def reanalyze_experiment(results_dir: Path, output_dir: Path, radii: list[float]):\n",
    "    all_metrics = {}\n",
    "\n",
    "    for file in results_dir.glob(\"run_*_*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        impl = data[\"implementation\"]\n",
    "        pareto_front = np.array(data[\"pareto_front\"], dtype=float)\n",
    "\n",
    "        # parÃ¢metros originais do experimento\n",
    "        num_obj = data.get(\"num_obj\") or None\n",
    "        divisions = data.get(\"divisions\") or None\n",
    "\n",
    "        if num_obj is None or divisions is None:\n",
    "            # tenta pegar do summary se nÃ£o estiver em cada arquivo\n",
    "            # fallback: usar valores globais do experimento\n",
    "            summary_file = results_dir / \"summary.json\"\n",
    "            if summary_file.exists():\n",
    "                with open(summary_file, \"r\") as sf:\n",
    "                    summary = json.load(sf)\n",
    "                params = summary.get(\"parameters\", {})\n",
    "                num_obj = params.get(\"num_obj\", 2)\n",
    "                divisions = params.get(\"divisions\", 10)\n",
    "            else:\n",
    "                num_obj, divisions = 2, 10  # defaults\n",
    "\n",
    "        ref_pts = generate_reference_points(num_obj, divisions)\n",
    "\n",
    "        all_metrics.setdefault(impl, {})\n",
    "\n",
    "        for r in radii:\n",
    "            res = reanalyze_coverage_for_radius(pareto_front, ref_pts, r)\n",
    "            all_metrics[impl].setdefault(r, []).append(res)\n",
    "\n",
    "    # agregaÃ§Ã£o\n",
    "    aggregated = {}\n",
    "    for impl, rad_dict in all_metrics.items():\n",
    "        aggregated[impl] = {}\n",
    "        for r, metrics_list in rad_dict.items():\n",
    "            keys = [k for k in metrics_list[0].keys() if k not in (\"radius\", \"points_in\", \"points_out\")]\n",
    "            mean_metrics = {}\n",
    "            for k in keys:\n",
    "                vals = [m[k] for m in metrics_list]\n",
    "                mean_metrics[k] = float(np.mean(vals))\n",
    "            aggregated[impl][r] = mean_metrics\n",
    "\n",
    "    # salvar em JSON\n",
    "    with open(output_dir / \"reanalyzed_coverage.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"radii\": radii,\n",
    "            \"aggregated\": aggregated\n",
    "        }, f, indent=2)\n",
    "\n",
    "    # salvar em CSV\n",
    "    csv_file = output_dir / \"reanalyzed_coverage.csv\"\n",
    "    with open(csv_file, \"w\", newline=\"\") as fcsv:\n",
    "        fieldnames = [\"implementation\", \"radius\"] + list(next(iter(next(iter(aggregated.values())).values())).keys())\n",
    "        writer = csv.DictWriter(fcsv, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for impl, rad_dict in aggregated.items():\n",
    "            for r, metric_dict in rad_dict.items():\n",
    "                row = {\"implementation\": impl, \"radius\": r}\n",
    "                row.update(metric_dict)\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"ReanÃ¡lise concluÃ­da. Resultados salvos em {output_dir}\")\n",
    "\n",
    "# --- EXECUÃ‡ÃƒO ---\n",
    "reanalyze_experiment(RESULTS_DIR, OUTPUT_DIR, RADII)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec51fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Reanalisando experiment1 com referÃªncia [5, 5]...\n",
      "ðŸ”„ Reanalisando experiment2 com referÃªncia [5, 5, 5]...\n",
      "ðŸ”„ Reanalisando experiment3 com referÃªncia [5, 5, 5, 5]...\n",
      "ðŸ”„ Reanalisando experiment4 com referÃªncia [5, 5, 5, 5]...\n",
      "ðŸ”„ Reanalisando experiment5 com referÃªncia [5, 5, 5, 5, 5]...\n",
      "ðŸ”„ Reanalisando experiment6 com referÃªncia [5, 5, 5, 5, 5, 5]...\n",
      "ðŸ”„ Reanalisando experiment7 com referÃªncia [5, 5, 5, 5, 5, 5]...\n",
      "âœ… ReanÃ¡lise concluÃ­da. Resultados salvos em reanalyzed_hv\\reanalyzed_hv_summary.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from analysis.indicators import hypervolume\n",
    "\n",
    "# --- CONFIG ---\n",
    "EXPERIMENTS = [f\"experiment{i}\" for i in range(1, 8)]\n",
    "\n",
    "# pontos de referÃªncia (um por experimento 1..7, na mesma ordem)\n",
    "REFERENCE_POINTS = [\n",
    "    [5]*2, # exemplo para experiment1\n",
    "    [5]*3, # experiment2\n",
    "    [5]*4, # experiment3\n",
    "    [5]*4, # experiment4 (se 3 objetivos)\n",
    "    [5]*5, # experiment5\n",
    "    [5]*6, # experiment6\n",
    "    [5]*6  # experiment7\n",
    "]\n",
    "\n",
    "OUTPUT_DIR = Path(\"reanalyzed_hv\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def reanalyze_hv_experiment(results_dir: Path, ref_point: list[float]):\n",
    "    \"\"\"Recalcula HV mÃ©dio para cada implementaÃ§Ã£o em um experimento\"\"\"\n",
    "    stats = {}\n",
    "\n",
    "    for file in results_dir.glob(\"run_*_*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        impl = data[\"implementation\"]\n",
    "        pareto_front = np.array(data[\"pareto_front\"], dtype=float)\n",
    "\n",
    "        hv = hypervolume(pareto_front, ref_point)\n",
    "\n",
    "        stats.setdefault(impl, []).append(hv)\n",
    "\n",
    "    # agregaÃ§Ã£o: mÃ©dia por implementaÃ§Ã£o\n",
    "    aggregated = {}\n",
    "    for impl, values in stats.items():\n",
    "        aggregated[impl] = {\n",
    "            \"mean_hv\": float(np.mean(values)),\n",
    "            \"std_hv\": float(np.std(values)),\n",
    "            \"num_runs\": len(values)\n",
    "        }\n",
    "\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def reanalyze_all_experiments(base_dir: Path, experiments: list[str], ref_points: list[list[float]]):\n",
    "    summary = {\n",
    "        \"parameters\": {\n",
    "            \"experiments\": experiments,\n",
    "            \"reference_points\": ref_points\n",
    "        },\n",
    "        \"results\": {}\n",
    "    }\n",
    "\n",
    "    for exp, ref in zip(experiments, ref_points):\n",
    "        results_dir = base_dir / exp\n",
    "        if not results_dir.exists():\n",
    "            print(f\"âš  DiretÃ³rio {results_dir} nÃ£o encontrado, ignorando\")\n",
    "            continue\n",
    "\n",
    "        print(f\"ðŸ”„ Reanalisando {exp} com referÃªncia {ref}...\")\n",
    "        aggregated = reanalyze_hv_experiment(results_dir, ref)\n",
    "        summary[\"results\"][exp] = aggregated\n",
    "\n",
    "    # salvar em JSON\n",
    "    out_file = OUTPUT_DIR / \"reanalyzed_hv_summary.json\"\n",
    "    with open(out_file, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"âœ… ReanÃ¡lise concluÃ­da. Resultados salvos em {out_file}\")\n",
    "\n",
    "\n",
    "# --- EXECUÃ‡ÃƒO ---\n",
    "reanalyze_all_experiments(Path('.'), EXPERIMENTS, REFERENCE_POINTS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
